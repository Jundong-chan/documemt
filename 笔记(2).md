# GO语法基础

## nil与interface

### interface底层

分为两个部分

> 1 、iface  描述接口包含的方法
>
> 分为tab和data
>
> tab存储接口的类型和具体类型、实体化的方法地址
>
> data存储指向接口具体的值

> 2 、eface  描述一个空接口（不含方法的类型）
>
> 存储实例化变量的值和类型



### nil和空

> nil表示未初始化的空，没有实际指向的地址，指向地址为0

> 空表示初始化为类型的零值，并指向一个指定的地址，表示为空
>
> 空类型与nil无法用等值判断。

> 如果一个interface被struct实例化但是值为空，该interface与nil比较为false
>
> 带类型的空interface不等于nil

> nil只能与interface , map , slice , pointer , func ,channel 比较

### interface方法

> 实现了接收者是值类型的方法，相当于自动实现了接收者是指针类型的方法；
>
> 实现了接收者是指针类型的方法，不会自动生成对应接收者是值类型的方法;

理解：当结构体使用指针类型实现一个接口的部分方法，用值类型实现剩下的方法，**指针类型的结构体是可以转成该接口类型的。此时值类型的结构体是无法转成接口类型的**。

总结：值类型实现的方法可以当成指针方法用。指针类型的方法权利大，不能被当成值类型方法使用。



### golang中确保实现了某个接口的写法

`var _ helloService =&Hello{}`

### 断言

> 断言是对interface变量进行类型判断，如果使用ok，无论如何不会panic



### fmt.println()

> 括号内接收的是interface类型，如果是基本类型则会逐个打印其数据。
>
> 如果是自定义类型，则判断该类型是否实现了String()string方法，有则使用，没有则利用反射打印其所有内容

### interface实现多态

> 什么是多态：
>
> 不同对象使用同一种方法，有不同的效果

> 如何实现多态
>
> 在函数的参数中传入interface，然后传入不同的实例化对象，在函数内部调用这个接口的通用方法，则会根据传入的实例化对象进行调用。

### GO接口和C++接口有什么不同

> go的接口只是定义了一个规范不做具体的实现。
>
> C++的接口是纯虚函数，用来做多态的。
>
> GO接口是非侵入式的，C++的接口需要继承

## panic和recover

> 只能在defer func中使用recover捕获
>
> panic后会直接开始执行defer的逻辑，如果defer中没有recover，则退出函数的时候就会报panic
>
> recover只能恢复当前线程的panic



## 函数传参时值拷贝

#### Struct的方法定义

> 给一个函数加一个接收者，那么它就是方法

> 无论是指针还是值接收的方法，都可以用值对象或者指针对象去调用，由编译器去解引用或者取地址
>
> 调用方法一定会发生拷贝，值拷贝或者指针拷贝

> 传指针，主要是为了能够对结构体的变量进行修改，不会节省内存，因为可能会引发逃逸
>
> 传值，产生值拷贝，主要是为了函数内部的改动不影响到上层。

传指针和传引用都不会节省内存，因为传指针会发生逃逸，传引用相对好一点。

**对性能要求高且访问频次高的函数，尽量不要写成接口类型的方法，这样会造成多的内存逃逸或者值拷贝。**

#### 作为参数传入函数时，变量是值拷贝还是引用拷贝

> map和slice是引用类型，作为值传入函数还是可以改变外部的变量

> Map 使用make初始化，可以不指定初始大小，如果map只是使用var定义，那么map为nil，是不能往里面写数据的。
>
> slice使用make初始化，必须指定大小，可以不指定cap。当函数使用传值的slice，在函数内发生扩容现象，那么在函数内的变化不会应用到函数外部。
>
> 如果传指针的话，可以应用到外部。

> slice初始化的时候，如果初始化给定大小，那么都会变成0，并且如果往这个slice append元素的话，是从给定大小之后写数据的，并不会覆盖0



## channel

> chan分为只读和只写  <-chan  chan<- 以及可读可写 chan T

> 要用通信来共享内存

> 并发b





## Context

> 上下文，用于解决协程之间的退出和元数据的传递

> 种类：
>
> 可取消的：cancelCtx，timerCtx
>
> 不可取消的：emptyCtx, valueCtx

> 取消过程，调用cancel函数，此协程后面传递的都会被取消
>
> 取消原理：

## map原理



### 底层

> 返回的是一个*hmap指针，因此是引用类型

> 使用数据结构：hash table

> hash算法根据cpu支持的来选择，aes或者memhash

> hmap表示一个hash map ，存储map的长度，桶的对数，桶指针，旧桶的指针，溢出桶信息mapextra等

> mapextra存储着所有溢出桶的信息，只有当map的数据类型不含指针时才使用。为了避免gc不必要的递归扫描

> bmap表示一个桶结构，存储桶内8个元素的key和elem，以及8个tophash（hash值的高8位），高8位hash用于判断key在桶中的位置。

> 每个桶最多只能放8个元素



### key定位过程

> 1、生成key的hash (64位)

> 2、根据桶的对数大小B（2^B 为桶的总数），取hash值低B位，确定桶的编号
>
> *这里使用位运算的方法避开求余的做法。 `v:=hash%2^B`  相当于  `v:=(uintptr(1)<<B-1)&hash`   后者的位运算求 hash的低 B位数据。*

> 3、确定桶的地址后，判断旧桶大小，如果不为空则说明，正在扩容。
>
> 4、如果正在扩容，则取这个桶的tophash[0]，判断桶的状态，是否>4，小于4则说明桶被迁到新的地方了。
>
> 如果桶的状态正常则在旧桶中查找。

> 5、根据hash值的高8位确定桶中 key的位置（到tophash数组里找,不直接比较key的原因是为了快速找到位置）
>
> 6、如果找到，则比较对应位置的key是否一样，一样则返回，不一样则返回不存在。

> 7、如果tophash找不到，则判断有没有溢出桶，递归到溢出桶里寻找

> 8、还是没有找到，则返回零值的地址，如果找到，返回的是**h[key]的指针**



### 扩容

> 装载因子（初始元素个数/桶的总数量）：平均每个桶的装载个数，固定为6.5 ， 一个桶的上限是8

> 初始化map的时候，如果给定初始化长度，根据装载因子可以计算出map会分配多少个bucket
>
> 初始化元素个数<=2^B*6.5		得到B的大小，即log2^B为桶的总数。 [参考](https://studygolang.com/topics/13520)

> 扩容时机1：
>
> 当map达到装载因子的阈值时发生扩容。为了防止出现所有bucket的元素都快满了。
>
> 扩容策略：两倍扩容，B+1。  此时原来的所有元素都在Oldbucket

> 扩容时机2：
>
> 当map中的overflow bucket数量太多（大于2^B），元素又很少,没有达到装载因子的阈值，导致查找效率也很低。
>
> 另外开辟一个一样大小的bucket空间，所有的overflow的元素就可以紧密地排列

> 扩容过程：
>
> 分配新的buckets内存，将老的buckets挂在Oldbucket。
>
> 每次从old搬迁两个bucket到新的去。
>
> 迁移过程需要对key rehash以适应新的bucket

> 扩容大小 原来的2倍或不增大

### 遍历新老map(扩容时遍历)

> 生成随机的迭代器值

> 根据迭代器在bucket中遍历

> 判断top hash值得知是否正在扩容，当前key在扩容的话就到旧的bucket拿key放到新的bucket，然后继续遍历

由上可知，会导致随机遍历



### 读写安全

> map不能边读边写，线程不安全

> key的类型只要是能够用==比较的都可以，因此，除去map,slice,functions都可以

> float 类型作为key时，可能会导致精度问题



### Sync.Map

> 能够支持并发安全读写的map

> Sync.map定义就可以使用，即零值是有效的

> 思想：通过空间换时间，创建read map和 dirty map 两个进行读写分离。

> 基本使用
>
> ```go
> var m sync.Map   //不需要初始化就可以使用
> 	m.Store("name","wangjia")
> 	m.Store("age",5)
> 	m.Store("ID","333")
> 	id,_:=m.Load("ID")
> 	fmt.Println(id)
> 	m.Range(func(key,value interface{})bool{  //一旦返回false就会退出循环
> 		name:=key.(string)
> 		values,ok:=value.(string)
> 		if !ok{
> 			return false
> 		}
> 		fmt.Println(name,values)
> 		return true
> 
> 	})
> 	m.Delete("age")
> 	m.LoadOrStore("KD",2324)	//读取成功时不会有任何修改
> 	id,_=m.Load("KD")
> 	fmt.Println(id)
> ```

> 底层数据结构
>
> ```go
> type Map struct {
> 	mu Mutex
> 	read atomic.Value // readOnly
> 	dirty map[interface{}]*entry
> 	misses int
> }
> ```



#### 读

> 先读read map，如果没有，则去dirty map读，并将miss字段+1 ，当miss字段大于等于dirty的长度时，将dirty赋给 read map.

#### 写

>先向dirty map中写数据，等到read 没有命中会来dirty中找的，miss达到阈值就会复制回去。

#### 改/延迟删

>先到read map中找，如果找到，则直接改，或者直接置nil，read中找不到就到dirty中找到然后删除



## slice原理

### 底层

是一个strcut结构，里面有数组指针，len cap



### Append机制

当 s有多余空间，使用append写数据，但是接收返回值的是另一个变量，那么原来s的数据不会改变。

原因：append返回的是更改过的slice，底层数组还是原来s的。

```golang
package main

import "fmt"

func main() {
    s := []int{5}
    s = append(s, 7)
    s = append(s, 9)
    x := append(s, 11)
    y := append(s, 12)
    fmt.Println(s, x, y)
}
```

输出：[5 7 9] [5 7 9 12] [5 7 9 12]

> x输出被覆盖的原因：x 和y都对s进行操作，由于append是赋给x和y，因此s的len+1并没有赋给s。

> 输出S的时候，由于len还是原来的，因此显示没有变化。x和y都在同一个len位置操作。因此y会覆盖x

> 当append的时候发生扩容，x得到的是新的slice地址，y得到的也是新的slice，因此此时y的更改不会覆盖x

### 深浅拷贝





### 扩容机制

> 有资料说是2倍扩容，如果大于1024的时候，就采用1.25倍扩容方式。
>
> 但这个说法是不全面的。
>
> 根据go的源码，在进行扩容计算之后，还需要根据定义好的内存对齐表，进行调整得到最终的大小。



## byte与rune

> byte是 uint8的别名，表示一个字符的大小
>
> rune 是uint32的别名，表示一个4字节的大小

> 如果string里面有中文，那么需要将string转成[]rune



## 类型转换

### 类型

> 底层类型 分为命名类型和未命名类型
>
> 命名类型：
>
> uint8(byte) uint16 uint32 uint64 int int8 int16 int32(rune) int64 bool string float32 float64 complex64 complex128 

> 未命名类型(5种)：
>
> chan slice map pointer function interface 
>
> 其中引用类型为：chan slice map pointer

类型之间的转换，主要看该变量的底层类型之间能不能兼容

`type Myint int`

以上 Myint是基本类型，int是底层类型

> 通过反射查看底层类型。reflect.TypeOf(variable).Kind()

接口的断言本质也是类型转换

#### 类型别名

Uint8 别名是type

uint32别名是rune



### string转[]byte发生内存拷贝

[string转[]byte的陷阱](https://www.cnblogs.com/mushroom/p/8998538.html)

### Make 和new

> make一般用来初始化map和slice以及channel

> new是用来初始化一个类型的空间，返回这个空间的地址。

> 当赋予变量的是空结构，那么它的地址是一个go的全局私有变量zerobase的地址
>
> [参考](https://www.jianshu.com/p/e0fd84a59088)

## for range

> 使用for range 来遍历string , 每个v是rune类型

> 使用range遍历map的时候，得到的是随机的。
>
> 原理：

## 位运算

> 非操作是^ 有别于其他语言的 ~
>
> 

## uintptr和Unsafe.Pointer

### 类型

>uintptr是整型
>
>Unsafe.Pointer是通用指针类型

### 特性

>uintptr可以做指针运算，会被gc，gc不把它当作指针因此它无法持有对象
>
>Unsafe.Pointer可以转换成任何指针类型，不能做算数运算，所指向的内存不会被gc

### 使用

> 要做指针运算的时候，需要先转成Unsafe.Pointer，才能转成uintptr , 因为Unsafe.Pointer是通用指针类型

> 运算完成后，将指针转回Unsafe.Pointer后再转成正常的指针，再取值即可得到内容



## 内存逃逸

### 为什么会发生内存逃逸

> go的内存分配是在编译器编译的时候做逃逸分析，然后决定的，即决定变量分配到堆还是栈。

> 分析变量大于栈的生命周期，在其他地方被引用，则逃逸到堆。最后只能由GC来回收。

### 意义

> 做逃逸分析有利于合理分配变量所在内存的位置，不用不用程序员担心，缓解gc回收堆内存的压力。

### 什么情况下会发生

> 当函数/闭包 内部的变量在函数外部被引用则会发生逃逸，作为返回值一样。

> 当发送指针或者带有指针的值到channel的时候，因为不确定是哪个协程接收，因此会发生逃逸。如果是传值的话就不会，因为传值到channel，会发生值拷贝。

> 如果切片存储指针或者带指针的值，会导致切片的内容发生逃逸，指针引用的值会逃逸到堆上。

> 切片在发生扩容的时候一定会在堆上重新分配

> 调用interface类型里的方法时，会导致实例以及参数逃逸到堆，因为编译时不能确定该方法会被谁调用。

> 在分配的对象过大的时候也会在堆上分配。

> 无法确定其生命周期的变量，会分配到堆上。

> 用到反射取interface底层的数据类型时，会发生逃逸。fmt包就会如此

在堆上分配会慢于栈

### 如何检测

`go build -gcflags=-m xxx.go`





## 反射

> 指在程序运行过程中，对程序对接口变量的访问和修改的能力

> 不用反射不行？反射可以探知未知变量的类型，值，拥有的方法，并对其进行更改。

> 反射的坏处：
>
> 编译器对无法对反射代码进行类型检查等工作。
>
> 反射会降低性能，需要高效率的地方不要使用反射。
>
> 代码可读性差

> 反射的好处：动态修改和调用运行期间的变量。

### 反射的使用



## MPG模型

#### M代表内核线程

> M是内核线程的映射，与内核线程是一对一的关系，保存着内核线程的地址

#### P代表处理器

> 提供运行环境，

#### G代表协程

> 保存协程的运行堆栈

#### Sched调度器

> 负责协调他们之间的调度

#### 调度策略：

> M绑定P获得执行协程的环境，从P的局部队列中不断取出G进行调度。
>
> G会分配到每个P的本地队列，如果满了就放到全局队列。
>
> 如果一个G执行时，遇到I/O阻塞，那就会被挂到epoll轮询器上，等待可用。期间M会执行其他的G
>
> 如果一个M遇到内核的中断被挂起，那么P可能会寻找别的M去执行
>
> 涉及到的寻找其他的G/M，这是由调度器去计时控制的，如果一个G执行太久也会被调度出来。



## 匿名函数/字段



## 锁机制



### 内存管理

> 思想：采用线程缓存的分配方法。启动时先向操作系统申请一大块内存空间，然后根据规则切割成小块，根据对象大小按需分配，回收时自己管理，不还给操作系统。

> 好处：减少往来开销，按需分配有利于减少内存碎片化

> 内存结构：从高地址到底地址依次是
>
> 栈，堆，全局未初始化变量bss，全局已初始化data，程序代码块text

> **所说的内存管理指的是对 堆 的管理，因为它不会像栈那样自动回收**

>申请的一大块内存空间由三部分组成

> Spans / bitmap / arena
>
> arena：是堆内存，由一个个page 组成
>
> Spans存放指针集合mspan，用于映射arena的内存。
>
> bitmap用于标记gc的回收

> spans的映射（分配）方式是怎么样的？
>
> 总结：按需分配
>
> 将内存块分为67种大小不同的块，由链表分别串起来。需要分配的时候就按需分配即可。
>
> 如果小的span分配完了，就会选择一个大的，分成多个小的连起来。

## GC回收

### 占用CPU

### STW

> 回收堆的内存



## Sync.pool



## 进程，协程和线程

> 进程是操作系统分配资源和调度的基本单位，每个进程之间都有独立的代码和地址空间。
>
> 进程间通讯方式：
>
> 共享内存，管道，信号量，消息队列，PRC，

> 线程：处理器调度和执行的基本单位，不能离开进程，共用进程的地址空间。耗费的资源较少,线程的切换开销比进程要小。
>
> 多线程程序有一个崩溃的话，进程也会崩溃。
>
> 线程拥有自己的寄存器和栈，堆是共享的
>
> 通讯方式：通过进程的共享内存进行通讯

> 协程：可以称作用户态的线程，比线程更加轻量，初始占2K大小，协程的上下文切换只涉及到三个寄存器，PC,SP,DX
>
> 协程有特殊的调度机制：
>
> 充分利用内核线程进行并发（MPG模型）



## Linux线程模型







## Yaml/toml







# GO调试工具

## trace

## pprof





# 数据库



## Sql和NoSql

> 什么是关系型？
>
> 字段之间的逻辑关系

> SQL
>
> 指具有关系型的约束的数据库。
>
> 严格的表，每个记录的数据字段要一致
>
> 有完整性约束，事务的一致性，支持多个表联合查询

> 场景：对数据有严格一致性，完整性要求的。比如银行，机场等需要保存重要数据的。

> Nosql
>
> 指非关系型的数据库
>
> 没有ACID一致性约束，分布式，适于存储数据的结构不固定的，大量的数据。
>
> 使用类JSON的文档存储，有集合的概念，相当于表，但是集合里的数据没有完整性约束。
>
> 多变的数据，适用于社交网络，客户管理，等数据不固定化的场景



### NoSQL数据库

#### 列式存储

> 只存储列，适用于某列或几列的查询。方便存储结构化和半结构化数据

> hbase  big table

#### 文档数据库

>旨在将半结构化数据存储为文档，存储类似JSON的数据，可以建立索引，但是查询性能不高

> Mongodb

#### 图形数据库

> 可以在SQL和NoSql数据库中构建，存储的是图结构，适用于社交网络，关系图谱的存储。

> 利用图算法构建

#### 内存键值存储

> 用于处理数据大量访问的场景，数据无结构化，查询速度快

> redis,memcaced

## mysql

整个mysql的架构

![image-20210715213927808](/Users/jundongchen/Desktop/mainly/Note/image-20210715213927808.png)

### 引擎

#### innodb

>- 支持事务，并且每条语句都当做事务处理
>- 默认支持行级锁，使用索引实现，提高并行读取性能，没有命中索引的时候，退化成行锁
>- 支持外键
>- 主键的索引是聚集索引，B+树的叶子结点存放的是数据，因此叶子结点的排列顺序也是物理节点的排列顺序

#### Myisam

>- 不支持事务
>- 有表锁，没有行锁
>- 不支持外键
>- 主键的索引是非聚集索引，B+树的叶子结点存放的是数据的指针，多一次读内存的时间
>- 非事务管理表，提供高速存储和检索，查询场景远大于修改时可以用

### 锁

#### 排他锁

> 事务加上锁时，只能由该事务对这个数据进行操作，其他事务不能加锁

#### 共享锁

> 事务加上锁后，只能进行读取，其他事务也可以加共享锁，不能加其他锁。



### 事务

#### ACID原则

> A：原子性，一个事务要么执行成功要么失败回滚（回滚使用undo log实现）

> C：一致性，事务的执行必须使数据保持一致的状态。所有事务对一个数据的读取的结果一致（undolog实现）
>
> I：隔离性，其他事务无法读取到另一个事务未提交的修改 (数据库锁机制实现)
>
> D：持久性，事务提交成功，对数据库的修改是永久的 （通过redo log实现）

#### 并发一致性问题

> 丢失修改：一个事务提交并修改了另一个事务未提交的数据

> 脏读：一个事务读取了另一个事务修改了但未提交的数据，这个数据被回滚

> 不可重复读：事务在多次读取同一个数据发现得到的结果不一致(update)

> 幻读：事务在多次查询时，得到的结果 集不一样（insert/delete）



#### 四种隔离级别

>未提交读：其他事务可以读取一个事务未提交的执行结果

>已提交读：事务的执行结果只能在提交后才能被看见（避免脏读），通过加锁实现

>可重复读：事务在执行过程中可以多次读取同一个数据而不发生变化（避免不可重复读）（默认隔离级别）

>串行化：强制事务串行化执行。

#### 如何实现读已提交和可重复读

> 通过Readview（当前活跃的事务）。给数据库拍一个快照（读取所有的事务ID）
>
> 当事务要操作的数据的事务ID处在已提交的集合中，那么该数据可见
>
> 如果这个数据在事务正在执行区间，先判断这个事务id是否已经执行完，没有则不可见
>
> 如果事务在未开始的区间，这个数据不可见
>
> **既然数据不可见，那怎么显示旧版本的数据（通过undo log。记载了数据和对应事务的版本，也用于回滚）**

### 事务的提交和回滚

> 事务进行提交后，就没有回滚的说法了。一个事务，要么提交要么回滚

> 事务的执行过程：
>
> 1、begin / start transaction
>
> 2、输入语句，会一个一个执行（更新到这个事务的版本上）undo log 已经记录语句的执行
>
> 3、如果出现执行出错，**出错的语句是不能执行成功的，但是其他语句可以，如果后面commit的话**
>
> 4、最后执行commit或者rollback



### 三大范式

#### 第一范式

> 表的每个属性不可分

#### 第二范式

> 表中每个非主属性完全依赖于主属性，比如学生姓名做主键，那么学号，课程名不能完全依赖于主属性

#### 第三范式

> 表中非主属性不能出现在其他表的非主属性

### 三大范式为了解决

> 为了解决数据的完整性问题，减少数据冗余，让数据插入，删除，修改正常



### 存储过程

> 一段预先编译好的SQL语句集
>
> 安全，效率高，减少网络通信负担



### 三个删除语句的区别

> delete
>
> **删除部分或全部数据，可利用日志回滚，保留表结构和索引，会触发 触发器，速度慢**
>
> Delete from 

> Truncate
>
> **删除所有数据，不能回滚，不会触发触发器，快，保留表结构**和索引

> drop
>
> **删除所有数据，删除表结构，索引，约束，不能回滚，不会触发触发器**



### Undo log /redo log /binlog

#### Undolog

> undolog 记录数据的所有版本，使用roll_pointer指针指向上一个版本
>
> 用于实现MVCC多版本并发控制，实现事务的隔离机制等

#### redolog

> Redo log 记录所有数据的修改，无论事务有没有提交，修改过都会记录下来。当崩溃的时候，就会用来恢复，为了事务的持久性，事务提交前都会写这个。
>
> 处于存储引擎层的日志。引擎层在处理修改数据的时候，先写redo log ，再通知引擎层提交事务写入磁盘。
>
> 记录方式：固定大小文件，超过则覆盖。

#### binlog

> binlog 记录数据变化的逻辑日志，记录的是语句，server层执行的，追加方式写入。
>
> 只有当事务提交的时候才会写binlog，binlog持久化到磁盘也有时机的，可自己配置
>
> 用途：主从复制，也可以用来恢复某个时间段的数据。

#### 比较

> Redo log 是inno DB引擎独有
>
> 归档日志binlog
>
> 重写日志redo log
>
> 回滚日志 undo log

## 索引种类

#### 普通索引

#### 唯一索引

> 有唯一性约束，但是可以为null

#### 主键索引

> 只能是主键，有唯一性

#### 多列索引

> 多个索引复合，满足最左前缀匹配原则

#### 覆盖索引

> 查询条件完全命中索引，不需要回表查询

### 分布式事务

#### 什么是分布式事务？

> 指的是事务的参与者，支持事务的服务器，资源服务器位于不同 的分布式系统上的不同节点。
>
> 总的来说，是为了保证不同数据库的一致性

### 为什么会产生分布式事务？

> 原因1: 服务节点多。完成一个事务要在多个服务节点上完成。
>
> 原因2 ：多个资源节点，完成一个数据操作事务涉及到多个不同机器上的数据库

### 2pc协议

> 分为两个阶段
>
> 准备提交阶段：事务管理器发出预备提交的请求，让执行事务的节点进行执行，然后返回状态
>
> 提交阶段：节点需要返回就绪或者未就绪给事务管理器，事务管理器发起提交事务或者回滚事务的命令，节点去执行，返回结果。

> 缺点：**事务管理器角色重要，如果死机则导致节点的资源一直等待提交，阻塞。如果有的节点没有收到提交的命令，那就会导致数据不一致。（有的提交了有的没提交）**
>
> **预提交时会阻塞等待提交的命令，因此不适合高并发场景**，**强一致性**

#### 3pc协议

> 提交阶段变成准备提交（尝试分配资源），预提交（执行事务），提交（commit）,给了一个缓冲时机，不用一开始就提交事务。
>
> **强一致性**

#### TCC协议

> 分三个阶段
>
> Try阶段：所有执行事务的节点尝试执行事务
>
> Confirm阶段：如果try阶段返回成功，则确认执行事务，如果遇到执行失败，无论如何都要进行重试。
>
> Cancel阶段，如果try阶段有返回失败的，则执行取消，所有节点无论如何都要不断尝试取消事务。

> 使用场景：适合对数据有严格一致性要求的场景，因为会一直执行直到成功（最终一致性）
>
> 适合高并发

#### 本地消息表

本地执行事务成功后，将事务放到本地消息表，推到kafka，让其他机器去同步事务的执行。

> 适用于BASE理论，即对一致性要求不算高的场景。

#### 可靠消息事务（适用于高并发）

> 将两个事务通过消息中间件进行解耦。

>- A先发送一个事务消息给 消息队列，消息队列缓存后，返回确认，A开始执行自己的任务，执行完后发送提交给消息队列。
>- 消息队列开始向B投递事务消息，等待B执行完它的事务那一部分，返回应答给消息队列。
>- 如果B一直没有处理，或者超时，或者失败，则消息队列会进行计时然后重复发送。
>- 如果多次为成功，需要人工干预。
>
>好处：解耦，适用于高并发，适用于一个事务需要A和B参与。最终一致性。

#### 阿里的Seata

> 要点：将分布式事务当成是一个包含若干个分支事务的全局事务。

##### 组成

> TC：事务的协调者，管理全局分支事务的状态，用于全局性事务的提交和回滚。
>
> TM：事务管理者，负责开启、提交或回滚事务
>
> RM：资源管理器，向TC**注册**分支事务，上报分支事务的状态，**接收**TC的命令来提交或回滚事务

过程：

>1、服务A中的 **TM** 向 **TC** 申请开启一个全局事务，**TC** 就会创建一个全局事务并返回一个唯一的 **XID**
>
>2、服务A中的 **RM** 向 **TC** 注册分支事务，然后将这个分支事务纳入 **XID** 对应的全局事务管辖中
>
>3、服务A开始执行分支事务
>
>4、服务A开始远程调用B服务，此时 **XID** 会根据调用链传播
>
>5、服务B中的 **RM** 也向 **TC** 注册分支事务，然后将这个分支事务纳入 **XID** 对应的全局事务管辖中
>
>6、服务B开始执行分支事务
>
>7、全局事务调用处理结束后，**TM** 会根据有误异常情况，向 **TC** 发起全局事务的提交或回滚
>
>8、**TC** 协调其管辖之下的所有分支事务，决定是提交还是回滚

总之，就是通过远程调用传播同样的分支事务ID，然后由TC全局管理，决定最后提交还是回滚

全局统一管理事务的状态和提交及回滚，不需要交给业务层去管理事务。

相对于2pc说：Seata采用中间件方式管理事务，而2pc是在数据库层进行事务的控制

### 优化数据库

#### 分库分表



#### SQL语句优化

> 查找慢查询日志，执行超过10秒的语句都会被记录下来

> 使用expain +SQL语句，查看语句的优化情况，是否使用了索引，表的读取顺序，等等

> 使用limit限制返回的数据

> 将大的联合查询，分成几个单表查询，然后在代码层面将结果筛选，有利于缓存的再次利用
>
> 避免使用select *

#### 索引优化

> 尽量避免索引失效的场景

> 索引失效的场景：
>
> - 以%开头的like语句  （%代表0个或多个字符，条件前缀存在不确定性）
> - **OR语句前后没有同时使用索引**
> - 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）；
> - 对于多列索引，必须满足 **最左匹配原则**/最左前缀原则 (最左优先，eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)；
> - 索引列有函数运算
> - **如果MySQL估计全表扫描比索引快，则不使用索引**（比如非常小的表）**由查询优化器决定**

#### 适合创建索引的场景

> - 经常查询的字段
> - 连接字段
> - 经常被用作最大最小值
> - 经常出现在 orderby groupby disdinct

### where/select/orderby/groupby/having顺序

> 1、from+join

> 2、where

>3、groupby

> 4、having

> 5、select

> 6、orderby

> 7、limit

## 主从复制

实现原理：

- 主服务器 **binary log dump 线程**：将主服务器中的**数据更改**（增删改）日志写入 Binary log 中；
- 从服务器 **I/O 线程**：负责从主服务器读取binary log，并写入本地的 **Relay log**；
- 从服务器 **SQL 线程**：负责读取 **Relay log**，解析出主服务器已经执行的数据更改，并在从服务器中重新执行（Replay），保证主从数据的一致性



## Redis

> 基于内存的单线程数据库

### 持久化策略

#### AOF

> 机制：fork一个进程将所有的写命令记录下来。

> 缺点：恢复数据需要重新执行所有命令，比较慢，占用空间大

> 优点：默认一秒写一次，丢失数据的数据量低，风险低。当文件较大的时候，会执行重写，优化文件中的命令。

> 场景：完整性较好，适合数据重要的场景。

#### RDB(默认开启)

> 机制：fork一个子进程将数据持久化到本地文件（类似快照，对数据进行打标签）异步

> Dump.rdb

> 持久化策略也可以在conf文件中设置

> 触发时机：符合持久化策略的配置时，以及save,flushall,shut down时
>
> 缺点：保存快照的时间间隔如果太短，会影响redis的性能，如果太长，丢失数据时会多很多。

>好处：恢复大量数据时比较快，因为基于快照，有利于数据备份。

> 场景：适合在数据丢失容忍度高的情况

##### 当两个都开启时，使用AOF，因为它对数据完整性要求较高。

### 数据类型

#### 底层数据结构

#### SDS动态字符串：

> 使用场景：
>
> - 所有 非数字的key
> - 字符串数据类型的值
> - 所有非字符串数据类型中的字符串，比如 zset中的 key score string  ，这里的string可以用SDS实现
>
> 底层结构：
>
> len , free , buf，分别表示当前字符串的长度，字符串剩余的预分配空间，字符数组，以\0为结尾
>
> 好处：通过预分配长度，减少每次修改字符串需要重新分配内存的次数。
>
> 读取字符串不需要以\0为标志，直接读取len即可，因此字符串可以用于存储一些二进制数据。
>
> 每个字符串最大容量512M

#### ziplist压缩链表：

> 使用场景：
>
> 用于存储数据量小于512个，单个元素的大小小于64字节的场景。用于 list,zset,hash的存储
>
> 底层结构：
>
> Zlbyte、zllen、zltail、entry、tail五个部分，分别表示 压缩链表占的总长度，节点数量，头部到节点尾部的偏移量，节点结构，尾部标识。
>
> entry的结构是：pev_len ,encoding , content 分别表示前一个节点的长度（用于往前遍历），本节点的数据类型和长度，节点内容。
>
> 遍历：可以从前往后遍历（获取当前节点的len），也可以从后往前遍历（使用pevlen）。
>
> 删除/插入：找到对应节点的位置，然后执行插入删除，然后再次整理内存，同时，循环对每个节点的pevlen进行修改和判断，pevlen当前的长度能否记录下前一个节点占用的长度，否则要进行扩容。
>
> **好处：连续的存储空间（减少内存碎片化），可以前后访问，不需要存前后指针，减少内存浪费，访问速度快。**
>
> **总之：访问速度快，减少空间浪费。**
>
> **什么时候使用：当数据量小的时候，即当元素个数小于512或者元素的长度小于64字节时使用ziplist**

Hash table 字典

> 冲突的解决办法是链地址法
>
> 使用一个二维数组，数组每个存放该key以及冲突的所有key
>
> 必要时会进行rehash 扩容或则收缩

inset 整数集合

> 底层是三部分，一个是编码格式（都是不同长度的int类型），一个是len, 一个是内容（数组）
>
> 编码格式是根据数组中的数据进行升级，如果数组中有一个是int32，剩下的是int16，那么所有的类型都要升级为int32
>
> **为什么要使用**：当集合元素较少的时候有利于节省空间，查找的时候使用二分，当数据量少的时候 O(logn)比O(1)的效果要好。

skip list 跳表+字典

> 为了加快单链表的O(N)查找速度，在单层链表基础上，加多几层链表，有序的结构，时间复杂是O(logn) 
>
> **跳表加快范围查询的速度，字典加快单体查询的速度。**
>
> 当插入一个节点的时候，先创建一个节点存储score和number，然后同时在跳表和字典中找到这个节点的插入位置，并同时指向这个节点的地址（**即跳表和字典同一个节点共用一个地址**）。
>
> 同时跳表通过抛硬币决定其层数，比如正面则在第二层创建一个同样的节点，再抛，正面加一层，直到反面停止。这也是 复杂度 O(logn)的由来。

> 查找：从最上层开始找，比节点数大则向右找，比节点数小则向左下找

#### Key-value

> 简单的键值对
>
> 底层维护的是hash字典
>
> string类型的话，底层是使用了SDS数据结构来存储（使用 object encoding string类型的key 输出的是 embstr）。key-string就放在hash字典。

> 如果是int，那就使用int 类型

#### list

> 底层：双向链表，左右可进可出，可做数组使用
>
> 原理：
>
> ziplist是一个压缩链表，内存紧密排列，
>
> 头部：记录总长度，头尾偏移量，元素个数等信息
>
> 节点：头部记录编码类型
>
> 3.2版本前
>
> 使用zip list存储（元素个数不超过256/每个元素大小小于64字节）
>
> 当不满足条件时，使用linklist双向链表
>
> 3.2版本之后
>
> **直接使用quicklist**，也就是ziplist和双向链表的结合。
>
> 双向链表的每个节点，都是一个ziplist
>
> **加快链表过长时候的访问速度**

#### set(集合，不有序)

> 当数据量少的时候使用intset(整数集合,并且个数不少于512)
>
> 当数据量变大的时候，使用hash table
>
> 保证唯一：判断hash 的score，如果一样再判断value值，一样则存在，插入失败
>
> 使用情况：当元素类型是整数的时候，使用inset先保存，如果数量过多，或者元素有字符串，则使用hash table

#### zset（有序集合）

>当数据量少的时候使用ziplist（元素小于64字节，数量少于128时），连续内存，插入的时候可以做到有序插入
>
>当数据量大的时候，使用跳表(skiplist)（本质上是跳表+字典）
>
>查询过程：zset数据有 key  score value ，score表示排名的依据，key表示集合的名字
>
>查询的时候，先根据number到字典里查到对应的score(O(1))，再用score到跳表中计算对应排名
>
>保证有序：跳表的生成过程就是按照有序来的
>
>**为什么使用跳表+字典：跳表范围查询效率高，字典单个查询效率高，zset需要进行排名以及查询单个字段的排名。两个数据结构中同一个节点的地址是共用的。**
>
>**举例：zrank的时候同时需要范围查询来计算这个number的名次，又需要快速查到这个number对应的score（字典），因此需要两者结合。**

#### hash

> 当数据量少的时候使用ziplist
>
> 当数据量大时候，使用hash table
>
> 使用ziplist时，怎么存放：key和value紧挨在一起。

#### bitmap



### 哨兵机制

1、主从复制

> redis支持主从复制，主数据库负责读和写，从数据库只能读。
>
> 数据一致性：主数据库先执行，然后同步给从数据库执行。同步分两种：一是在刚开始连接上时进行全量同步（RDB文件），然后进行增量同步（环形缓冲区）主从记录自己写和读的位置，如果从读的慢，就可能被主数据库覆盖完缓冲区。

2、服务高可用

> 通过哨兵机制，保证主从数据库的服务高可用。选举
>
> 运行期间：每个哨兵会监控**所有的主从库**，周期性发送ping，哨兵之间通过pub/sub机制通信（发布/订阅）
>
> 下线：当ping不通的时候，哨兵认为它是主观下线，当多个哨兵判断主观下线时，则这个实例是客观下线。
>
> 选举：选举依据是 **预先设置的优先级、各从库的同步进度、从库的ID号**（依次排序）
>
> 选举出来后，谁来通知？此时需要一个哨兵成为leader的哨兵，代表新的主库发起转换。leader哨兵需要其他哨兵投票产生。
>
> 选举成功：将新主库的数据发送到其他从库让他们进行同步。

### I/O多路复用（多个I/O共用一个线程）

#### 为什么

> i/o操作时而需要时而空闲；i/o线程不能像高并发那样随意申请

#### 是什么

> 是一种同步I/O模型，实现一个线程可以监控多个文件句柄，如果没有状态变化，就会阻塞这个线程。

#### select

> 一句话：使用bitmap存储操作符fd，最大支持1024个

> 问题：
>
> - 1024限制高并发的需求
> - 每次都要遍历fd数组，查看哪些已经预备好 可读可写了
> - 整个数组需要每次从内核态到用户态相互拷贝，消耗大
>
> 为什么涉及到用户态和内核态的拷贝？
>
> 因为fd 的状态check需要用到内核态的函数。

#### poll

> 基于链表存储，没有最大1024限制
>
> 其他和select无区别

#### epoll（event poll linux独有，Redis在用）

> 通过事件驱动，哪个监听的i/o流发生I/O状态改变，就会通知。不需要轮询fd数组/链表
>
> 连接数有限制，但是比较大，够用
>
> 原理：使用红黑树存储所有要监听的fd，传入内核，保存在内核
>
> 然后内核监听到读写状态变化，则返回一个链表，是可操作的fd

> ET模式
>
> 只会提示一次，当一个fd有数据可以读取，如果第一次提醒时没有处理，则下一次不会再提醒了，直到fd的状态发生变化。**所以在ET模式下，第一次提醒时一定要读取完。**

> LT模式
>
> 只要fd还有数据可以读，则每一次都会返回这个fd，提醒用户去操作。

### 缓存问题

#### 雪崩(指大量key失效)

> 同一时间段，有大量缓存过期，导致大量请求直接到数据库
>
> 解决：给缓存的key尽量错开过期时间。

#### 穿透

> 顾名思义，直接穿透过去，故redis中没有对应的缓存。

> 通常指的是，请求一个不存在的数据，导致直接穿过缓存到数据库。

> 解决1：给没有命中的key设置一个空值，短暂过期。
>
> 解决2: 使用布隆过滤器，存储所有的key，然后对不存在的key进行直接返回查询为空值。

#### 击穿（指大量请求某个失效的key）

>缓存中某一个key失效，突然有大量请求访问这个key，导致请求透传到数据库。
>
>按理说，第一个请求从数据库拿到数据后，应该会更新缓存数据，但是在构建缓存的时间里，已经有大量请求进行童谣的操作，造成的数据库并发量已经无法阻止了。
>
>解决1：当拿到缓存过期时，不要立即取Db，先set一个互斥锁，然后自己进入数据库取数据更新缓存，将锁解开即可，
>
>其他请求发现上锁了，就等待一下，然后尝试读取缓存。
>
>解决2: 使用限流，保护后端



## MongoDB

> 基于bson的文档数据库





# 网络

![TCP](C:\Users\Ethan\Desktop\note\quanliangwork\imgs\TCP.gif)

## TCP握手挥手

#### TCP握手

> 第一次：客户端发送 SYN=1 , seq=x
>
> 第二次：服务器发送 ACK=1,SYN=1,ack=x+1,seq=y
>
> 第三次：客户端发送 ACK=1, ack=y+1

#### TCP挥手

> 第一次：客户端发送 seq=w, FIN=1
>
> 第二次：服务器发送 ACK=1, ack=w+1, seq=v
>
> .......
>
> 第三次：服务器发送 seq=k, FIN=1
>
> 第四次：客户端发送 ACK=1, ack=k+1
>
> 等待2个报文段最长寿命的时间，如果没有收到服务器的第三次报文则说明一切正常。

#### 第三次握手和第四次挥手的必要性

> 为了确保双方收发信息的功能都正常

## TCP/UDP的比较

> TCP是面向连接的可靠的流式传输协议
>
> 有拥塞控制，有数据确认机制
>
> 一对一，需要维护连接
>
> 首部20字节

>UDP是无连接的，非可靠的数据报传输协议
>
>支持多对多，一对多，多对一通信
>
>首部8字节



## 流量控制

### 以滑动窗口协议控制

> 分为发送窗口，接收窗口，拥塞窗口。

> 发送窗口的大小上限为 接收窗口和拥塞窗口中的较小值

> 接收窗口的大小在确认包中的窗口字段，单位是字节

> 拥塞窗口的大小由拥塞控制算法调整

> 发送窗口  是 滑动窗口的可发送部分。滑动窗口由待确认和可发送组成。

当接收窗口大小为0时，意味着发送方不能发送数据，但是每隔一段时间发送方会发送一个1字节大小的探测数据包，来获取接收窗口的大小。



## 拥塞控制

### 慢开始

> 初始拥塞窗口的大小是1个MSS(一次能传输的最大报文长度)
>
> 初始门限值为16
>
> 每经过一个传输轮次（TTL）, 就将拥塞窗口大小*2，直到遇到初始门限值，就进入拥塞避免

### 拥塞避免

> 每经过一个传输轮次，就拥塞窗口大小+1

> 在慢开始和拥塞避免阶段，只要出现网络拥塞情况（没有收到确认），就会将慢开始门限设置为原来的一半(不小于2)，拥塞窗口的大小设置为1，然后继续执行慢开始算法

### 快重传

> 当连续收到三个重复确认的时候，则说明发送的包丢失，则立即重传这个包，不用等到重传计时器到期。

> 重复确认：当接收方收到失序的报文时，就会发起想要的序号的报文的重复确认。



### 快恢复

> 当出现快重传后，**将慢开始门限的值减半，并继续执行拥塞避免算法。**

> 不执行慢开始的原因是，认为没有出现网络拥塞



## TCP粘包、拆包

### 粘包原因

> 1、TCP基于字节流，TCP连接可复用，会发送多种数据包，数据包的边界就变得模糊
>
> 2、TCP使用Nagle算法：1）只有上一个分组得到确认，才会发送下一个分组。2）收集多个小分组，在一个确认到来后，一起发送。
>
> 3、接收方未及时接收，多个包堆积
>
> 4、数据包过大，超过缓冲区大小或者超过TCP最大报文长度，被分割发送。
>
> UDP基于数据报

### 解决粘包问题

> 1、消息封装消息头（自行）
>
> 2、设置定长消息，服务端每次读取固定长度消息
>
> 3、写入消息边界分隔符

## 五层协议

### 应用层

> http(80),https(443),DNS(53),ftp(21)

### 传输层

> TCP/UDP

### 网络层

> Ip、ARP、NAT、RIP、ICMP

> ARP协议：使用Ip地址查找MAC地址；可以通过代理ARP访问局域网外的mac地址
>
> ICMP协议：用于检测消息是否可达（ping）

### 数据链路层

> 交换机，网卡，网桥

### 物理层

> 中继器，集线器





## HTTPS建立连接过程

> 1、客户端发送请求，携带 一组客户端支持的加密规则
>
> 2、服务器收到后，从中选出一个**对称加密算法和hash算法**，以及数字证书（包含域名，公钥，CA机构等信息）发送给客户端
>
> 3、客户端收到后，使用证书的**CA机构的公钥**来验证证书的合法性。再看看是否过期，域名是否匹配。验证通过后，生成一个**会话密钥**，使用服务器的**公钥进行加密**，再使用协商好的Hash算法对握手信息进行摘要计算，一起传给服务器
>
> 4、服务器收到后，使用私钥解密出密钥，验证摘要信息。
>
> 5、双方使用会话密钥进行通信

使用SSL/TLS建立安全连接，端口443

## DNS域名解析过程

分为迭代查询和递归查询两种。

#### 迭代查询（常用）

> 本地服务器请求根服务器有递归和迭代

#### 递归查询

>主机向本地域名服务器的查询一般都是采用递归查询。
>
> 所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其他服务器查询

涉及到TCP/UDP两个协议



## WebSocket

### 特点

> 应用层协议，浏览器和服务器之间，浏览器可使用
>
> 全双工通信
>
> 基于TCP，复用HTTP握手通道，表现为：客户端通过HTTP握手请求服务器升级为WebSocket协议
>
> 建立后，每次传输不需要完成的协议头

### 建立连接过程

> 1、客户端请求协议升级，只支持 HTTP的Get
>
> ```http
> GET / HTTP/1.1
> Host: localhost:8080
> Origin: http://127.0.0.1:3000
> Connection: Upgrade
> Upgrade: websocket
> Sec-WebSocket-Version: 13
> Sec-WebSocket-Key: w4v7O6xFTi36lq3RNcgctw==
> ```
>
> 2、服务端响应协议升级
>
> ```http
> HTTP/1.1 101 Switching Protocols
> Connection:Upgrade
> Upgrade: websocket
> Sec-WebSocket-Accept: Oy4NRAQ13jhfONC7bP8dTKb4PTU=
> ```
>
> - `Sec-WebSocket-Key`：与后面服务端响应首部的`Sec-WebSocket-Accept`是配套的，提供基本的防护，比如恶意的连接，或者无意的连接。
> - `Sec-WebSocket-Key` 的计算伪代码 ：``Sec-WebSocket-Key``
>
> 3、传输数据格式，帧
>
> 1. 发送端：将消息切割成多个帧，并发送给服务端；
> 2. 接收端：接收消息帧，并将关联的帧重新组装成完整的消息；
>
> 4、opcode标志位表示数据传输的状态，终止，数据交换，心跳包



### restful风格的API

> 执行删除，修改，查询等操作的uri是一样的，只是请求的方式和请求体的内容不一样。
>
> 动作不体现在uri上，通过http请求方式体现就好。
>
> ```http	
> 我们可以这样设计成类似于：
> 
> http://mengkang.net/?method=comment.del&id=x ①
> 
> http://mengkang.net/comment/del/id/x ②
> 
> 或者其他形式的 url。
> 
> 而 RESTful Api 则是：
> 
> [DELETE] http://mengkang.net/comments/1 ③
> ```

> 宗旨：还原URL（统一资源定位符）的本质，不应该包含动作

### http请求方式

> ### get / post 区别
>
> > - 传参
> >
> >   ​	传参方式：get通过url传递参数，post通过请求体传递参数。
> >
> >   ​	传参长度：url传参有长度限制，请求体传参没有。其实HTTP协议没有对url和请求体的长度进行限制，对它们长度进行限制大多是浏览器和服务器的原因。
> >
> > - 安全
> >
> >   ​	post相较于get是稍微安全一些的，因为数据在地址栏和浏览器历史记录都是不可见的。
> >
> >   ​	从传输的角度来说，只要使用HTTP协议传输都不安全，因为HTTP在网络上都是明文传输的，想要安全的传输就要使用HTTPS。
> >
> > - 缓存
> >
> >   ​	get可以缓存，post不能缓存。
> >
> > - **编码方式**
> >
> >   ​	get请求只能进行url编码(application/x-www-form-urlencoded)，而post支持多种编码方式(application/x-www-form-urlencoded、multipart/form-data、application/json、text/xml)
> >
> > - 发送数据包数量
> >
> >   ​	有些浏览器，post会将请求头和请求体分开发送，先发送请求头，服务端返回100状态码再发送请求体，所以有些浏览器post会有两次请



## 从输入Url到获取页面的全过程

> 1、浏览器进程发起进程间通讯，到网络进程，网络进程查询本地缓存，查不到就发起网络请求。
>
> 查询DNS。浏览器DNS缓存--->操作系统DNS缓存---->读取本地Host文件---->向本地域名服务器进行查询---->发起递归查询或迭代查询
>
> 查询到会写入相应的缓存中
>
> 2、浏览器得到IP地址后发起三次握手。如果是HTTP协议还需要建立SSL连接
>
> 3、浏览器根据响应的内容，解析数据，调用渲染进行进行渲染显示



# 操作系统

## 进程和线程



## 大端小端

> 大端指的是：高位保存在低地址中，地位保存在高地址中

> 小端指的是：低位保存在低地址，高位保存在高地址

> 在计算机中，一个存储单元指的是一个字节，因此小于等于一个字节的数据是不会受到大小端的影响的。

网络字节序是大端

大小端由CPU的设计决定



## 进程间通信



## 网络轮询机制

### epoll



### SHELL

> 用户和内核沟通的桥梁





## 栈空间和堆空间

为什么在栈上分配内存会比在堆上分配快很多？

> 堆适合不可预知大小的内存分配。但是为此付出的代价是分配速度较慢，而且会形成内存碎片。
>
> 栈内存分配则会非常快。栈分配内存只需要两个CPU指令：“PUSH”和“RELEASE”，分配和释放;
>
> 而堆分配内存首先需要去找到一块大小合适的内存块，之后要通过垃圾回收才能释放

#### 栈空间的增长方向

> 从高地址往低地址增长

#### 堆空间的增长方向

> 从低地址往高地址增长

# 数据结构

## 正则表达式



# 消息中间件

## kafka

### 架构

### 消息不重复，按顺序





# 负载均衡



# GOweb框架







# 微服务相关

### 分布式定理（CAP）

C 一致性

> 所有的读操作能够返回最新的数据。证明分布式系统中，所有数据的状态都是一致的

A可用性

> 非故障节点在合理的时间内进行响应（不是错误或者相应超时）。即可用性好

P 分区容错性

> 当网络出现分区的时候，系统能够继续正常工作。

## jwt签发token可以控制过期

> jwt签发后，无法废除某个正常的token

> 配合Redis可以做到，废除token

> 1、用户登录后，签发一个**永久**的token，然后将用户唯一标识写入redis作为自动过期的key.
>
> 2、当用户携带token访问时，先验证token，如果正确，则查找redis，看是存在对应的key，不存在则返回**会话过期**。存在则刷新redis中的过期时间，达到频繁操作免登录
>
> 3、如果是删除账号或者退出登录，则删除用户在redis中的key

> 同时前端主动删除cookie（一般不会

# 算法

###  二叉搜索树的插入

采用递归插入或者顺序查找插入

```go
// func insertIntoBST(root *TreeNode, val int) *TreeNode {
//     if root==nil{
//         root=new(TreeNode)
//         root.Val=val
//         root.Right=nil
//         root.Left=nil
//         return root
//     }
//     if val>root.Val{
//         root.Right=insertIntoBST(root.Right,val)
//     }
//     if val<root.Val{
//         root.Left=insertIntoBST(root.Left,val)
//     }
//     return root
// }
//循环调用的方法
func insertIntoBST(root *TreeNode, val int) *TreeNode {
    if root ==nil{
        root :=new(TreeNode)
        root.Val=val
        return root
    }
    root1 :=new(TreeNode)
    root1=root

    for root1!=nil{
        if root1.Val<val{
            if root1.Right==nil{
                root1.Right=new(TreeNode)
                root1.Right.Val=val
                break;
            }
            root1=root1.Right
        }else{
            if root1.Left==nil{
                root1.Left=new(TreeNode)
                root1.Left.Val=val
                break;
            }
            root1=root1.Left
        }
    }
    return root

}
```

卡住的点：不断遍历，却将遍历的节点赋值为nil，再对nil节点写入数据，是不会应用到原来的树。



### 前缀树

路由的存储，是从将请求方法作为根，然后每个路径的单词作为节点。匹配到同节点就往下构建新节点。


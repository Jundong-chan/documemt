https://blog.51cto.com/tchuairen/1855090

#### 1、概念

分布式流式处理平台，高吞吐，可持久化，可水平扩展（集群支持热扩展），低延迟，容错（支持副本）

分布式消息传递系统（消息发布订阅/观察者模式），支持海量数据

#### 2、使用场景

- 日志收集

使用kafka收集 分布式系统中各个服务的日志数据，通过kafka以统一接口的方式开放给consumer

- 消息系统

解耦生产者消费者，异步处理数据

- 用户活动跟踪

用户的操作状态和路径可以通过信息传递给kafka，然后由订阅者去订阅这些数据，进行实时分析。

- 运营指标，系统的出错反馈。报警
- 流式处理

#### 3、技术优势

容错性，可靠性。可以做集群和主从复制。



#### 4、topic分区处理

主题分区处理是让消息的处理不受单个服务器的限制



#### 5、topic和partition 和消费者之间的关系

通常来讲消息模型可以分为两种 队列和发布-订阅式。 队列的处理方式是 一组消费者从服务器读取消息一条消息只有其中的一个消费者来处理。在发布-订阅模型中消息被广播给所有的消费者接收到消息的消费者都可以处理此消息。Kafka为这两种模型提供了单一的消费者抽象模型 消费者组 consumer group。 消费者用一个消费者组名标记自己。 一个发布在Topic上消息被分发给此消费者组中的一个消费者。 假如所有的消费者都在一个组中那么这就变成了queue模型。 假如所有的消费者都在不同的组中那么就完全变成了发布-订阅模型。 更通用的 我们可以创建一些消费者组作为逻辑上的订阅者。每个组包含数目不等的消费者 一个组内多个消费者可以用来扩展性能和容错。正如下图所示

![image-20210411172731018](/Users/jundongchen/Downloads/Waking-Up-master/image-20210411172731018.png)

上面提到的消息模型

- 队列：同名的消费者组员瓜分消息
- 发布订阅：广播消息给多个消费者组(不同名)



#### 6、整个流程

![image-20210412093608048](/Users/jundongchen/Downloads/Waking-Up-master/image-20210412093608048.png)



1、写入方式

Producer 采用的是push的方式，将消息送入broker, broker将消息放到 指定的partition ，并且是按顺序存放的方式，属于磁盘的顺序存储，效率高。

2、分区存储

kafka集群 维护每个主题的分区的日志文件。 内容都是追加上去的，分区里的每条消息都按照时间顺序分配到一个递增的消息编号，叫做**偏移量**，能够用来定位一条消息。不同分区之间的偏移量是独立的。

原始的消息内容和分配的偏移量以及其他一些元数据信息最后都会存储到分区日志文件中。

![image-20210412094456752](/Users/jundongchen/Downloads/Waking-Up-master/image-20210412094456752.png)

3、主题

一个主题可以被分成多个分区并放在不同的broker上，每个消息的类别是一个主题。一个主题一般会有多个消息订阅者。



#### 4、主题分区原因

1、消费者可以以分区为单位进行并行读取，提高了消息系统的并发量。

2、分区分布在各个集群中，方便数据量的扩展。



#### 5、分区的顺序性

kafka规定，一个分区的消息只能由消费者组中的一个消费者拿到，但是不会固定这个消费者获取，下一个消费者可能是这个组中的另一个消费者拿。**并且一个分区的消息会发给多个消费者组。**类似广播

如何保证：设置一个消费者组只有一个消费者，这样这个消费者就可以按顺序拿到分区的数据。如果要实现订阅，就使用一个消费者放一个



#### 6、生产者消息选择分区的规则

指定了 partition 时，使用

未指定partition ，但是指定了key 则对key 的value进行hash 得到 partition

当partition 和 key都未指定 则使用轮询选择。



#### 7、生产者发送消息的过程

![image-20210412122014231](/Users/jundongchen/Downloads/Waking-Up-master/image-20210412122014231.png)

1）producer先从zookeeper的 “/brokers/…/state”节点找到该partition的leader
2）producer将消息发送给该leader
3）leader将消息写入本地log
4）followers从leader pull消息，写入本地log后向leader发送ACK
5）**leader收到所有ISR中的replication的ACK后，增加HW（high watermark，最后commit 的offset）并向producer发送ACK**

**有同步和异步两种模式。**

同步：生产者等待leader下ISR中的的follower 同步完这个消息，leader返回ack的时候，生产者才继续自己的事。

异步：生产者发送消息给leader后就可以返回了。生产者通过一个回调函数来处理结果。



#### 8、术语

Offset : 消息偏移量，每个消息都标记上一个叫偏移量的东西。

AR(Assigned Repllicas) : 所有的副本

ISR (In-Sync Replicas) : 所有与leader保持一定同步的副本（包括leader），是AR的子集

OSR : 与leader同步滞后的follower 的集合(不包括leader)  AR=ISR+OSR

ISR 和OSR集合里的副本可能会相互转换，有可能有follower落后成为 OSR

HW : 表示高水位线 ，是一个偏移量（offset），消费者只能拿到 HW之前的消息。生产者最新写入的消息如果还没有达到备份数量，对消费者是不可见的。

LogStartOffset  : 消息开始的offset

LEO : LogEndOffset  表示当前log文件中下一条将要写入的消息的offset , **kafka的log文件是数据文件，不是日志文件**

![image-20210412134604166](/Users/jundongchen/Downloads/Waking-Up-master/image-20210412134604166.png)

LW (low watermark ) : 低水位，表示AR集合中最小的logStartOffset值。

LSO (log stable offset) : 稳定偏移，LSO之前的消息都是已经提交确认的。主要用于事务。消费者可以配置 读取的模式 (read_commit) 和 (read_uncommit) ，设置成读已提交的时候，只能读取 LSO之前的消息。

如果设置成读未提交，则只能读取到HW之前的消息。对于生产者开启的事务未提交的数据也可见，可读。

**不同消费者组的消费者可以到同一个partition 中，根据自己的offset 去读取对应的的消息。所以消息一般都会持久化到kafka本地的。用户可以设置消息在kafka上的过期时间**



#### 9、消费者消费消息过程

消费者获取数据**采用pull**的方式，主动从broker中读取消息。

这样做的**好处**：消费者可以根据自己处理消息的速率来读取消息。

**坏处**：当broker没有消息可以读取的时候，消费者可能会陷入阻塞。为了避免这种情况，拉请求中有参数，允许消费者请求在等待数据到达的“长轮询”中进行阻塞（并且可选地等待到给定的字节数，以确保大的传输大小）。

消费者是以consumer group消费者组的方式工作，由一个或者多个消费者组成一个组，共同消费一个topic。每个分区在同一时间只能由group中的一个消费者读取，但是多个group可以同时消费这个partition。

消费者在消费完消息的之后，会进行 commit offset ，提交位移，老的版本是将offset提交到zk上保存，新的版本是将 offset 提交到broker中保存。

提交有自动提交和手动提交：

自动（默认）：自动提交是设置一个提交间隔，提交的时机在pull的时候，但是如果在时间间隔之内出现宕机则可能会出现重复消费。因为这个offset的更新丢失，下次消费的还是这个消息。

手动提交：每pull一个消息下来，就提交一次。有同步版本和异步版本。同步会阻塞（可以一直提交直到成功），异步会只尝试一次。**可以使用异步失败后进行同步提交。**



#### 10、消息的顺序性体现

kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的**一个**

费者消费，保证了消费时也是有序的。

整个topic不保证有序

**消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?**
**offset+1**



#### 11、分区器，序列化器，拦截器

分区器：根据消息的键值对消息进行判断处于哪个分区。分区策略有三种：

1、消息指定了parttion 就直接送过去

2、没有指定，但是指定key，则对key的value 进行hash ，根据结果送到对应的partition

3、没有指定key , 则使用轮询选择partition



序列化器：键序列化器和值序列化器，将键和值都转为二进制流 还有反序列化器 将二进制流转为指定类型数据。

拦截器:两个方法。 doSend()方法会在序列化之前完成 。onAcknowledgement()方法在消息确认或失败时调用 。可以添加多个拦截器按顺序执行。

**调用顺序: 拦截器doSend() -> 序列化器 -> 分区器**



#### 12、重复消费的情况

当消费者 在消费完一个消息后，没有commit offset , 就挂掉了，导致下次会再消费这个消息。

解决：很难，通过消费者本地记录是否消费过。



#### 13、漏消费消息

消费者没有处理完消息 提交offset(自动提交偏移 未处理情况下程序异常结束)



#### 14、kafkaConsumer是非线程安全的，那么怎么样实现多线程消费？

每个线程一个消费者



#### 15、简述消费者与消费组之间的关系

消费者从属与消费组，**消费偏移以消费组为单位**。每个消费组可以独立消费主题的所有数据，同一消费组内消费者共同消费主题数据，每个分区只能被同一消费组内一个消费者消费。



#### 16、创建topic时如何选择合适的分区数？

根据集群的机器数量和需要的吞吐量来决定适合的分区数

